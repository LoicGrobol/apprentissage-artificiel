---
jupyter:
  jupytext:
    formats: ipynb,md
    split_at_heading: true
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- LTeX: language=fr -->

<!-- #region slideshow={"slide_type": "slide"} -->
TP 3‚ÄØ: `scikit-learn`
=======================

**Lo√Øc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)

<!-- #endregion -->

```python
from IPython.display import display
```

## scikit-learn‚ÄØ‚ÄØ?

[scikit-learn](https://scikit-learn.org/stable/index.html).

scikit-learn est une biblioth√®que Python d√©di√©e √† l'apprentissage artificiel qui repose sur
[NumPy](https://numpy.org/) et [SciPy](https://scipy.org/). Il est √©crit en Python et
[Cython](https://cython.org/). Il s'interface tr√®s bien avec [matplotlib](https://matplotlib.org),
[seaborn](https://seaborn.pydata.org/) ou [pandas](https://pandas.pydata.org/) (qui lui-m√™me marche
tr√®s bien avec [plotnine](https://plotnine.readthedocs.io/)). C'est devenu un incontournable du
*machine learning* et des *data sciences* en Python.

Dans ce notebook on se limitera √† la classification, une partie seulement de ce qu'offre
scikit-learn.

La classification est souvent utilis√©e en TAL, par exemple dans les t√¢ches d'analyse de sentiment,
de d√©tection d'√©motion ou l'identification de la langue.

On va faire de l'apprentissage *supervis√©* de classifieurs‚ÄØ: l'id√©e est d'apprendre un mod√®le √†
partir de donn√©es r√©parties en classes (une classe et une seule pour chaque exemple), puis de ce
servir de ce mod√®le pour r√©partir parmi les m√™mes classes des donn√©es nouvelles

Dit autrement, on a un √©chantillon d'entra√Ænement $\matchcal{D}$, compos√© de $n$ couples $(X_{i},
Y_{i}), i=1,‚ÄØ‚Ä¶, n$ o√π les $X_{i}$ sont les entr√©es (en g√©n√©ral des **vecteurs** de traits ou
*features*) et les $y_{i}$ seront les sorties, les classes √† pr√©dire. On cherche alors dans une
famille $\mathbb{M}$ de mod√®les un mod√®le de classification $M$ qui soit le plus performant possible
sur $\matchcal{D}$.

`scikit-learn` offre beaucoup d'algorithmes d'apprentissage. Vous en trouverez un aper√ßu sur
[cette carte](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) et sur ces
listes : [supervis√©](https://scikit-learn.org/stable/supervised_learning.html) / [non
supervis√©](https://scikit-learn.org/stable/unsupervised_learning.html).

Mais `scikit-learn` offre √©galement les outils pour mener √† bien les √©tapes d'une t√¢che de
d'apprentissage‚ÄØ:

- Manipuler les donn√©es, constituer un jeu de donn√©es d'entra√Ænement et de test
- Entra√Ænement du mod√®le
- √âvaluation
- Optimisation des hyperparam√®tres

```python
%pip install -U scikit-learn
```

## Un premier exemple

### Les donn√©es

C'est la cl√© de voute du *machine learning*, vous le savez n'est-ce pas‚ÄØ? Nous allons travailler
avec un des jeux de donn√©es fourni par scikit-learn‚ÄØ: [le jeu de donn√©es de reconnaissance des
vins](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset)

C'est plus facile pour commencer parce que les donn√©es sont d√©j√† nettoy√©es et organis√©es, mais vous
pourrez bien s√ªr par la suite [charger des donn√©es venant d'autres
sources](https://scikit-learn.org/stable/datasets/loading_other_datasets.html).

```python
from sklearn import datasets
wine = datasets.load_wine()
type(wine)
```

(La recommandation des d√©veloppeureuses de `scikit-learn` est d'importer uniquement les parties qui
nous int√©resse plut√¥t que tout le package. Notez aussi le nom `sklearn` pour l'import.)

Ces jeux de donn√©es sont des objets `sklearn.utils.Bunch`. Organis√©s un peu comme des dictionnaires
Python, ces objets contiennent‚ÄØ:

- `data` :¬†array NumPy √† deux dimensions d'√©chantillons de donn√©es de dimensions `(n_samples,
  n_features)`, les inputs, les X
- `target` :¬†les variables √† pr√©dire, les cat√©gories des √©chantillons si vous voulez, les outputs,
  les y
- `feature_names`
- `target_names`

Et d'autres trucs comme

```python
print(wine.DESCR)
```

```python
wine.feature_names
```

Si on a install√© `pandas`

```python
%pip install -U pandas
```

On peut convertir ces donn√©es en `DataFrame` pandas si on veut.

```python
import pandas as pd

df = pd.DataFrame(data=wine.data,columns=wine.feature_names)
df['target']=wine.target
df.head()
```

Mais l'essentiel est de retrouver nos inputs $X$ et outputs $y$ n√©cessaires √† l'apprentissage.

```python
X_wine, y_wine = wine.data, wine.target
```

```python
X_wine.shape
```

```python
y_wine
```

Vous pouvez s√©parer les donn√©es en train et test facilement √† l'aide de
`sklearn.model_selection.train_test_split` (voir la
[doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split))

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size=0.3)
y_train
```

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.hist(y_train, align="right", label="train") 
plt.hist(y_test, align="left", label="test")
plt.legend()
plt.xlabel("Classe")
plt.ylabel("Nombre d'exemples")
plt.title("R√©partition des classes") 
plt.show()
```

Il ne faut pas h√©siter √† recourir √† des repr√©sentations graphiques quand vous manipulez les donn√©es.
Ici on voit que la r√©partition des classes √† pr√©dire n'est pas homog√®ne pour les donn√©es de test.  
On peut y rem√©dier en utilisant le param√®tre `stratify`, qui fait appel √†
[`StratifiedShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)
pour pr√©server la m√™me r√©partition des classes dans le train et dans le test.

```python
X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size=0.25, stratify=y_wine)
plt.hist(y_train, align="right", label="train") 
plt.hist(y_test, align="left", label="test") 
plt.legend()
plt.xlabel("Classe")
plt.ylabel("Nombre d'exemples")
plt.title("R√©partition des classes avec √©chantillonnage stratifi√©") 
plt.show()
```

## Entra√Ænement

L'√©tape suivante est de choisir un algorithme (un *estimator* dans la terminologie de scikit-learn),
de l'entra√Æner sur nos donn√©es (avec la fonction `fit()`) puis de faire la pr√©diction (avec la
fonction `predict`).

Quelque soit l'algo choisi vous allez retrouver les fonctions `fit` et `predict`. Ce qui changera ce
seront les param√®tres √† passer au constructeur de la classe de l'algo. Votre travail portera sur le
choix de ces param√®tres.

Exemple un peu bateau avec une m√©thode de type SVM.

```python
from sklearn.svm import LinearSVC
clf = LinearSVC()
clf.fit(X_train, y_train)
```

```python
clf.predict(X_test)
```

## √âvaluation

On fait l'√©valuation en confrontant les pr√©dictions sur les `X_test` et les `y_test`. La fonction
`score` nous donne l'exactitude (*accuracy*) moyenne du mod√®le.

```python
clf.score(X_test, y_test)
```

Pour la classification il existe une classe bien pratique :¬†`sklearn.metrics.classification_report`

```python
from sklearn.metrics import classification_report

y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

## ‚úçÔ∏è Exo ‚úçÔ∏è


1. Refaites une partition train/test diff√©rente et comparez les r√©sultats
2. Essayez un autre algo de classification ([un SVM √† fonction de base
   radiale](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) par exemple) et
   comparez les r√©sultats.
   - Voir [le tuto sur les noyaux
     SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_kernels.html) pour une id√©e de
     ce que √ßa signifie d'utiliser un RBF.

## Validation crois√©e

Pour am√©liorer la robustesse de l'√©valuation on peut utiliser la validation crois√©e
(*cross-validation*). `scikit-learn` a des classes pour √ßa.

```python
from sklearn.model_selection import cross_validate, cross_val_score
print(cross_validate(LinearSVC(), X_wine, y_wine)) # infos d'accuracy mais aussi de temps
print(cross_val_score(LinearSVC(), X_wine, y_wine)) # uniquement accuracy
```

## Optimisation des hyperparam√®tres

L'optimisation des hyperparam√®tres est la derni√®re √©tape. Ici encore `scikit-learn` nous permet de
le faire de mani√®re simple et efficace.¬†Nous utiliserons `sklearn.model_selection.GridSearchCV` qui
fait une recherche exhaustive sur tous les param√®tres donn√©s au constructeur. Cette classe utilise
aussi la validation crois√©e.

```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

param_grid =  {'C': [0.1, 0.5, 1, 10, 100, 1000], 'kernel':['rbf','linear']}
grid = GridSearchCV(SVC(), param_grid, cv = 5, scoring = 'accuracy')
estimator = grid.fit(X_wine, y_wine)
estimator.cv_results_
```

```python
df = pd.DataFrame(estimator.cv_results_)
df.sort_values('rank_test_score')
```

## Classification de textes

Le [dataset 20
newsgroups](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html)
est un exemple de classification de textes propos√© par `scikit-learn`. Il y a aussi [de la
doc](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) sur
les traits (*features*) des documents textuels.

La classification avec des techniques non neuronales repose en grande partie sur les traits
utilis√©s pour repr√©senter les textes.

```python
from sklearn.datasets import fetch_20newsgroups

categories = [
    "sci.crypt",
    "sci.electronics",
    "sci.med",
    "sci.space",
]

data_train = fetch_20newsgroups(
    subset="train",
    categories=categories,
    shuffle=True,
)

data_test = fetch_20newsgroups(
    subset="test",
    categories=categories,
    shuffle=True,
)
```

```python
print(len(data_train.data))
print(len(data_test.data))
```

Ici on a un jeu de 2373 textes cat√©goris√©s pour train. √Ä nous d'en extraire les features d√©sir√©es.
Le mod√®le des [sacs de
mots](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)
est le plus basique.

Attention aux valeurs par d√©faut des param√®tres. Ici par exemple on passe tout en minuscule et la
tokenisation est rudimentaire. √áa fonctionnera mal pour d'autres langues que l'anglais. Cependant,
presque tout est modifiable et vous pouvez passer des fonctions de pr√©traitement personnalis√©es.

```python
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(stop_words="english")
X_train = vectorizer.fit_transform(data_train.data) # donn√©es de train vectoris√©es
y_train = data_train.target
X_train.shape
```

Voil√† la t√™te que √ßa a

```python
X_train[0, :]
```

Euh


La t√™te que √ßa a

```python
print(X_train[0, :])
```

```python
X_test = vectorizer.transform(data_test.data)
y_test = data_test.target
```

Pour l'entra√Ænement et l'√©valuation on reprend le code vu auparavant

```python
clf = LinearSVC(C=0.5)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

[TF‚ãÖIDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
est un raffinement de ce mod√®le, qui donne en g√©n√©ral de meilleurs r√©sultats.

```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    sublinear_tf=True,
    max_df=0.5,
    stop_words='english'
)
X_train = vectorizer.fit_transform(data_train.data) # donn√©es de train vectoris√©es
y_train = data_train.target
X_train.shape

X_test = vectorizer.transform(data_test.data)
y_test = data_test.target

clf = LinearSVC(C=0.5)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

## ü§ñ Exo ‚ÄØü§ñ

### 1. Un projet complet

L'archive [`imdb_smol.tar.gz`](data/imdb_smol.tar.gz) (aussi disponible [dans le
d√©p√¥t](https://github.com/LoicGrobol/apprentissage-artificiel/blob/main/slides/06-scikit-learn/data/imdb_smol.tar.gz))
contient 602 critiques de films sous formes de fichiers textes, r√©parties en deux classes‚ÄØ:
positives et n√©gatives (mat√©rialis√©es par des sous-dossiers). Votre mission est de r√©aliser un
script qui‚ÄØ:

- Charge et vectorise ces donn√©es
- Entra√Æne et compare des classifieurs sur ce jeu de donn√©es

L'objectif est de d√©terminer quel type de vectorisation et de mod√®le semble le plus adapt√© et quels
hyperparam√®tres choisir. Vous pouvez par exemple tester des SVM comme ci-dessus, [un mod√®le de
r√©gression
logistique](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html),
[un arbre de
d√©cision](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html),
[un mod√®le bay√©sien
na√Øf](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) ou
[une for√™t d'arbres de
d√©cision](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).


### 2. D'autres traits

Essayez avec d'autres *features*‚ÄØ: La longueur moyenne des mots, le nombre ou le type d'adjectifs,
la pr√©sence d'entit√©s nomm√©es, ‚Ä¶

Pour r√©cup√©rer ce genre de *features*, vous pouvez regarder du c√¥t√© de [spaCy](http://spacy.io/)
comme pr√©traitement de vos donn√©es.
