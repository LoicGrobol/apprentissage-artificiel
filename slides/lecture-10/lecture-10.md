---
jupyter:
  jupytext:
    formats: ipynb,md
    split_at_heading: true
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.13.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- LTeX: language=fr -->

<!-- #region slideshow={"slide_type": "slide"} -->
Cours 10â€¯: RÃ©gression logistique
===============================

**LoÃ¯c Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)

2021-10-11
<!-- #endregion -->

```python
from IPython.display import display
```

## Classifieur linÃ©aire

## ğŸ˜´ Exo ğŸ˜´

Ã‰crire une fonction qui prend en entrÃ©e un vecteur de features et un vecteur de poids sous forme de
tableaux numpy $x$ et $w$ de dimensions `(n,)` et un biais $b$ sous forme d'un tableau numpy de
dimensions `(1,)` et renvoie $z=\sum_iw_ix_i + b$.

## La fonction logistique

## ğŸ“ˆ Exo ğŸ“ˆ

Tracer avec matplotlib la courbe reprÃ©sentative de la fonction logistique.

## Classifieur logistique

## ğŸ§  Exo ğŸ§ 

1\. Ã€ l'aide d'un lexique de sentiment (par exemple
[VADER](https://github.com/cjhutto/vaderSentiment)), Ã©crivez une fonction qui prend en entrÃ©e un
texte en anglais et renvoie sa reprÃ©sentation sous forme d'un vecteur de features Ã  deux traitsâ€¯:
nombre de mots positifs et nombre de mot nÃ©gatifs.

2\. Appliquer la fonction prÃ©cÃ©dente sur le mini-corpus IMDB

3\. Ã‰crire un classifieur logistique (en une fonction) qui prend en entrÃ©e les vecteurs de features
prÃ©cÃ©dents et utilise les poids respectifs $0.6$ et $0.4$ et pas de terme de biais. Appliquez ce
classifieur sur le mini-corpus IMDB et calculez son exactitude.

## Fonction de coÃ»t

## ğŸ“‰ Exo ğŸ“‰

Ã‰crire une fonction qui prend en entrÃ©e

- Un vecteur de features $x$ de taille $n$
- Un vecteur de poids $w$ de taille $n$ et un biais $b$ (de taille $1$)
- Une classe cible $c$ ($0$ ou $1$)

Et renvoie la log-vraisemblance nÃ©gative du classifieur logistique de poids $(w, b)$ pour l'exemple
$(x, c)$.

## Descente de gradient

## ğŸ§ Exo ğŸ§

Reprendre la fonction qui calcule la fonction de coÃ»t, mais faire en sorte qu'elle renvoie Ã©galement
le gradient en $(x, c)$.

## ğŸ˜© Exo ğŸ˜©

S'en servir pour apprendre les poids Ã  donner aux features prÃ©cÃ©dentes Ã  l'aide du mini-corpus LMDB
