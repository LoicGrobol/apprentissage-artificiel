---
jupyter:
  jupytext:
    formats: ipynb,md
    split_at_heading: true
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.13.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- LTeX: language=fr -->

<!-- #region slideshow={"slide_type": "slide"} -->
Cours 7‚ÄØ: `scikit-learn`
=======================

**Lo√Øc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)

2021-10-05
<!-- #endregion -->

```python
from IPython.display import display
```

## `scikit-learn‚ÄØ`‚ÄØ?

[`scikit-learn‚ÄØ`](https://scikit-learn.org/stable/index.html).

`scikit-learn‚ÄØ` est une biblioth√®que Python d√©di√©e √† l'apprentissage artificiel. Ce package est
d√©velopp√© sur licence libre. Il y a une forte proportion de fran√ßais parmi les d√©veloppeurs, le
projet est soutenu par l'INRIA¬†notamment.

`scikit-learn‚ÄØ` repose sur NumPy et SciPy. Il est √©crit en Python et Cython. Il s'interface tr√®s
bien avec `matplotlib`, `plotly` ou `pandas`. C'est devenu un incontournable du *machine learning*
et de la *datascience* en Python.

Dans ce notebook nous nous limiterons √† la classification, une partie seulement du package [scikit-learn](https://scikit-learn.org/stable/index.html).

La classification est souvent utilis√©e en TAL, par exemple dans les t√¢ches d'analyse de sentiment,
de d√©tection d'√©motion ou l'identification de la langue.

On va faire de l'apprentissage *supervis√©*, vous connaissez la chanson‚ÄØ: l'id√©e est d'apprendre un
mod√®le √† partir de donn√©es √©tiquet√©es et de pr√©dire la bonne √©tiquette pour une donn√©e inconnue du
mod√®le.

Dit autrement, on a un √©chantillon d'entra√Ænement compos√© de $n$ couples $Z_{i}=(X_{i}, Y_{i}),
i=1...n$ o√π les $X_{i}$ sont les inputs avec plusieurs traits et les $Y_{i}$ seront les outputs, les
cat√©gories √† pr√©dire.

L'objectif du probl√®me d'apprentissage est de trouver une fonction $g:X‚ÜíY$ de pr√©diction, qui
minimise les erreurs de pr√©diction.

`scikit-learn` offre beaucoup d'algorithmes d'apprentissage. Vous en trouverez un aper√ßu sur
[cette carte](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) et sur ces
listes : [supervis√©](https://scikit-learn.org/stable/supervised_learning.html) / [non
supervis√©](https://scikit-learn.org/stable/unsupervised_learning.html).

Mais `scikit-learn` offre √©galement les outils pour mener √† bien les √©tapes d'une t√¢che de
d'apprentissage‚ÄØ:

- Manipuler les donn√©es, constituer un jeu de donn√©es d'entra√Ænement et de test
- Entra√Ænement du mod√®le
- √âvaluation
- Optimisation des hyperparam√®tres

```python
%pip install -U scikit-learn
```

## Un premier exemple

### Les donn√©es

C'est la cl√© de voute du *machine learning*, vous le savez n'est-ce pas ? Nous allons travailler
avec un des jeux de donn√©es fourni par scikit-learn‚ÄØ: [le jeu de donn√©es de reconnaissance des vins](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset)

C'est plus facile pour commencer parce que les donn√©es sont d√©j√† nettoy√©es et organis√©es.

```python
from sklearn import datasets
wine = datasets.load_wine()
type(wine)
```

(La recommandation des d√©veloppeureuses de `scikit-learn` est d'importer uniquement les parties qui
nous int√©resse plut√¥t que tout le package. Notez aussi le nom `sklearn` pour l'import.)

Ces jeux de donn√©es sont des objets `sklearn.utils.Bunch`. Organis√©s un peu comme des dictionnaires
Python, ces objets contiennent‚ÄØ:

- `data` :¬†array NumPy √† deux dimensions d'√©chantillons de donn√©es (n_samples * n_features), les
  inputs, les X
- `target` :¬†les variables √† pr√©dire, les cat√©gories des √©chantillons si vous voulez, les outputs,
  les y
- `feature_names` 
- `target_names`

```python
print(wine.DESCR)
```

```python
wine.feature_names
```

Si on a install√© `pandas`

```python
%pip install -U pandas
```

On peut convertir ces donn√©es en `Dataframe` pandas si on veut.

```python
import pandas as pd

df = pd.DataFrame(data=wine.data,columns=wine.feature_names)
df['target']=wine.target
df.head()
```

Mais l'essentiel est de retrouver nos inputs X et outputs y n√©cessaires √† l'apprentissage.

```python
X_wine, y_wine = wine.data, wine.target
```

Vous pouvez s√©parer les donn√©es en train et test facilement √† l'aide de `sklearn.model_selection.train_test_split` ( voir la [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split))

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size=0.3)
y_train
```

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.hist(y_train, align="right", label="train") 
plt.hist(y_test, align="left", label="test")
plt.legend()
plt.xlabel("classe")
plt.ylabel("nombre d'exemples")
plt.title("r√©partition des classes") 
plt.show()
```

Il ne faut pas h√©siter √† recourir √† des repr√©sentations graphiques quand vous manipulez les donn√©es.
Ici on voit que la r√©partition des classes √† pr√©dire n'est pas homog√®ne pour les donn√©es de test.  
On peut y rem√©dier en utilisant le param√®tre `stratify`, qui fait appel √† [`StratifiedShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) pour pr√©server la m√™me r√©partition des classes dans le train et dans le test.

```python
X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine, test_size=0.25, stratify=y_wine)
plt.hist(y_train, align="right", label="train") 
plt.hist(y_test, align="left", label="test") 
plt.legend()
plt.xlabel("classe")
plt.ylabel("nombre d'exemples")
plt.title("r√©partition des classes avec √©chantillonnage stratifi√©") 
plt.show()
```

## Entra√Ænement

L'√©tape suivante est de choisir un algorithme (un *estimator*), de l'entra√Æner sur nos donn√©es train
(avec la fonction `fit()`) puis de faire la pr√©diction (avec la fonction `predict`).  
Quelque soit l'algo choisi vous allez retrouver les fonctions `fit` et `predict`. Ce qui changera ce
seront les param√®tres √† passer au constructeur de la classe de l'algo. Votre travail portera sur le
choix de ces param√®tres.

Exemple un peu bateau avec une m√©thode de type SVM.

```python
from sklearn.svm import SVC
clf = SVC(C=1, kernel="linear")
clf.fit(X_train, y_train)
```

```python
clf.predict(X_test)
```

## √âvaluation

On fait l'√©valuation en confrontant les pr√©dictions sur les `X_test` et les `y_test`. La fonction `score` nous donne l'exactitude (*accuracy*) moyenne du mod√®le.

```python
clf.score(X_test, y_test)
```

Pour la classification il existe une classe bien pratique :¬†`sklearn.metrics.classification_report`

```python
from sklearn.metrics import classification_report

y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

## ‚úçÔ∏è Exo ‚úçÔ∏è


1. Essayez un autre algo de classification (Un SVM polynomial par exemple) et comparez les r√©sultats.
2. Sur ce m√™me algo, refaites une partition train/test et comparez l'√©valuation avec les r√©sultats
   pr√©c√©dents. 

## Validation crois√©e

Pour am√©liorer la robustesse de l'√©valuation on va utiliser la validation crois√©
(*cross-validation*). `scikit-learn` a des classes pour √ßa. 

```python
from sklearn.model_selection import cross_validate, cross_val_score
print(cross_validate(SVC(C=1, kernel="linear"), X_wine, y_wine)) # infos d'accuracy mais aussi de temps
print(cross_val_score(SVC(C=1, kernel="linear"), X_wine, y_wine)) # uniquement accuracy
```

## Optimisation des hyperparam√®tres

L'optimisation des hyperparam√®tres est la derni√®re √©tape. Ici encore `scikit-learn` nous permet de
le faire de mani√®re simple et efficace.¬†Nous utiliserons `sklearn.model_selection.GridSearchCV` qui
fait une recherche exhaustive sur tous les param√®tres donn√©s au constructeur. Cette classe utilise
aussi la validation crois√©e.

```python
from sklearn.model_selection import GridSearchCV

param_grid =  {'C': [0.1, 0.5, 1, 10, 100, 1000], 'kernel':['rbf','linear']}
grid = GridSearchCV(SVC(), param_grid, cv = 5, scoring = 'accuracy')
estimator = grid.fit(X_wine, y_wine)
estimator.cv_results_
```

```python
df = pd.DataFrame(estimator.cv_results_)
df.sort_values('rank_test_score')
```

## Classification de textes

Le [dataset 20
newsgroups](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html)
est un exemple de classification de textes propos√© par `scikit-learn`. Il y a aussi [de la
doc](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) sur
les traits (*features*) des documents textuels.

La classification avec des techniques non neuronales repose en grande partie sur les traits
utilis√©es pour repr√©senter les textes.

```python
from sklearn.datasets import fetch_20newsgroups

categories = [ 'sci.crypt',
 'sci.electronics',
 'sci.med',
 'sci.space']

data_train = fetch_20newsgroups(
    subset='train',
    categories=categories,
    shuffle=True,
)

data_test = fetch_20newsgroups(
    subset='test',
    categories=categories,
    shuffle=True,
)
```

```python
print(len(data_train.data))
print(len(data_test.data))
```

Ici on a un jeu de 2373 textes cat√©goris√©s pour train. √Ä nous d'en extraire les features d√©sir√©es.
tf‚ãÖidf est un grand classique.

Attention aux valeurs par d√©faut des param√®tres. Ici par exemple on passe tout en minuscule et la
tokenisation est rudimentaire. √áa fonctionnera mal pour d'autres langues que l'anglais.

```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    sublinear_tf=True,
    max_df=0.5,
    stop_words='english'
)
X_train = vectorizer.fit_transform(data_train.data) # donn√©es de train vectoris√©es
y_train = data_train.target
X_train.shape
```

```python
X_test = vectorizer.transform(data_test.data)
y_test = data_test.target
```

Pour l'entra√Ænement et l'√©valuation on reprend le code vu auparavant

```python
clf = SVC(C=1, kernel="linear")
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

## ü§ñ Exo ‚ÄØü§ñ

### 1. D'autres traits
Essayez avec d'autres *features*‚ÄØ: La longueur moyenne des mots, le nombre d'adjectifs, la pr√©sence
d'entit√©s nomm√©es, ‚Ä¶

Pour r√©cup√©rer ce genre de features, vous pouvez regarder du c√¥t√© de [spaCy](http://spacy.io/).


### 2. Et les r√©seaux de neurones ?

`scikit-learn` permet d'utiliser un Multi-layer Perceptron (MLP). Et comme la biblioth√®que ne permet
pas d'utiliser un GPU pour les calculs, son utilisation est limit√©e √† des jeux de donn√©es de taille
moyenne.

`scikit-learn` n'est pas fait pour le *deep learning*. Il existe des biblioth√®ques associ√©es qui
permettent de combiner Keras ou pytorch avec `scikitlearn` n√©anmoins.

Essayez en suivant [la
doc](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)


Il y a encore plein d'autre choses marrantes √† faire avec `scikit-learn`¬†et on en verra, mais en attendant vous pouvez aller voir [leur exemple sur ce dataset](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) qui a de bien jolis graphiques.
