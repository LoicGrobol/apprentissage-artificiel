---
jupyter:
  jupytext:
    formats: ipynb,md
    split_at_heading: true
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- LTeX: language=fr -->

<!-- #region slideshow={"slide_type": "slide"} -->
Cours 3‚ÄØ: √âvaluer les mod√®les de langue √† n-grammes
===================================================

**Lo√Øc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)

2022-10-05
<!-- #endregion -->

## Pr√©c√©dently

```python
import random
import re
from collections import Counter, defaultdict
```

Rappel de [l'√©pisode pr√©c√©dent](../02-ngram_lms/ngram-lms-slides.py.md)‚ÄØ: on a vu comment utiliser
des fr√©quences de n-grammes issues d'un corpus pour g√©n√©rer du texte‚ÄØ:


(Cette fois-ci on va aussi garder la ponctuation, et comme l'expression r√©guli√®re devient compliqu√©,
on va y mettre [des commentaires](https://docs.python.org/fr/3/library/re.html#re.VERBOSE).)

```python
def crude_tokenizer_and_normalizer(s):
    tokenizer_re = re.compile(
        r"""
        (?:                   # Dans ce groupe, on d√©tecte les mots
            \b\w+?\b          # Un mot c'est des caract√®res du groupe \w, entre deux fronti√®res de mot
            (?:               # √âventuellement suivi de
                '             # Une apostrophe
            |
                (?:-\w+?\b)*  # Ou d'autres mots, s√©par√©s par des traits d'union
            )?
        )
        |\S        # Si on a pas d√©tect√© de mot, on veut bien attraper un truc ici sera forc√©ment une ponctuation
        """,
        re.VERBOSE,
    )
    return tokenizer_re.findall(s.lower())

crude_tokenizer_and_normalizer("La lune et les Pl√©iades sont d√©j√† couch√©es : la nuit a fourni la moiti√© de sa carri√®re, et moi, malheureuse, je suis seule dans mon lit, accabl√©e sous le chagrin.")
```

```python
def extract_ngrams(words, n):
    res = []
    for i in range(len(words)-n+1):
        # Tuple pour pouvoir s'en servir comme cl√© de dictionnaire et donc OK avec `Counter`
        res.append(tuple(words[i:i+n]))
    return res
```

```python
def read_corpus_for_ngrams(file_path, n):
    unigrams = Counter()
    ngrams = Counter()
    with open(file_path) as in_stream:
        for line in in_stream:
            words = crude_tokenizer_and_normalizer(line.strip())
            # Il nous faut bien `n-1` symboles de d√©but de phrase 
            words = ["<s>"]*(n-1) + words
            words.append("</s>")
            unigrams.update(words)
            ngrams.update(extract_ngrams(words, n))
    
    return unigrams, ngrams
```

```python
def get_ngram_probs(unigram_counts, ngram_counts):
    probs = defaultdict(dict)
    for (*previous_words, target_word), c in ngram_counts.items():
        probs[tuple(previous_words)][target_word] = c/unigram_counts[target_word]

    return dict(probs)
```

```python
def generate_from_ngrams(ngram_probs):
    # J'avais dit qu'on pouvait. Ici on le fait salement
    n = len(next(iter(ngram_probs.keys()))) + 1
    sent = ["<s>"] * (n-1)
    while sent[-1] != "</s>":
        # Essayer de bien r√©fl√©chir pour comprendre le `1-n`
        previous_words = tuple(sent[1-n:])
        candidates = list(ngram_probs[previous_words].keys())
        weights = [ngram_probs[previous_words][c] for c in candidates]
        sent.append(random.choices(candidates, weights)[0])
    # Pas la peine de renvoyer les tokens <s>
    return sent[n-1:-1]
```

Par exemple pour des bigrammes, voici ce qu'on g√©n√®re‚ÄØ:

```python
# Unpacking dans un appel de fonction, on va voir qui‚ÄØ? Oui, la doc.
bigram_probs = get_ngram_probs(*read_corpus_for_ngrams("data/zola_ventre-de-paris.txt", 2))

for _ in range(8):
    print(" ".join(generate_from_ngrams(bigram_probs)))
```

C'est pas *affreux* au sens o√π √ßa ressemble bien √† du langage, mais c'est pas *super* parce qu'il y
a quand m√™me plein de d√©fauts. Ce n'est pas tr√®s surprenant‚ÄØ: comme on l'a vu la derni√®re fois,
c'est un mod√®le tr√®s simpliste.


Les choses s'arrangent un peu si on prend un $n$ plus grand, par exemple $3$‚ÄØ:

```python
# Unpacking dans un appel de fonction, on va voir qui‚ÄØ? Oui, la doc.
trigram_probs = get_ngram_probs(*read_corpus_for_ngrams("data/zola_ventre-de-paris.txt", 3))

for _ in range(8):
    print(" ".join(generate_from_ngrams(trigram_probs)))
```

Alors pourquoi pas essayer avec plus‚ÄØ? Par exemple $5$‚ÄØ?

```python
pentagram_probs = get_ngram_probs(*read_corpus_for_ngrams("data/zola_ventre-de-paris.txt", 5))

for _ in range(8):
    print(" ".join(generate_from_ngrams(pentagram_probs)))
```

√áa a l'air bien‚ÄØ! Elles sont propres ces phrases‚ÄØ! Par exemple sur une ex√©cution de la cellule
pr√©c√©dente, j'ai obtenu `"alors seulement lisa rougit de se voir √† c√¥t√© de ce gar√ßon ."`

```python
!grep "Alors seulement Lisa rougit" "data/zola_ventre-de-paris.txt"
```

Oups

## Les plaies de l'apprentissage


On verra plus tard dans le cours une d√©finition formelle de l'apprentissage automatique/artificiel,
mais ce qu'on a ici c'en est‚ÄØ: on a con√ßu un programme qui ing√®re des donn√©es et essaie de produire
des r√©sultats qui reproduisent (avec des gros guillemets) ce qu'il y avait dans ces donn√©es. On dit
qu'il a **appris** ces donn√©es, qu'on appelle **donn√©es d'entra√Ænement**.


Alors ici quel est le probl√®me‚ÄØ? On voit que pour $n=5$, le mod√®le de langue √† $n$-grammes commence
√† avoir un comportement d√©sagr√©able‚ÄØ: il devient essentiellement une machine √† apprendre par c≈ìur le
corpus d'entra√Ænement. √áa n'est pas un mod√®le qui est *incorrect*‚ÄØ: il remplit bien le cahier des
charges. Par contre, c'est un mod√®le compl√®tement *inint√©ressant*‚ÄØ: √† ce compte-l√†, autant
directement tirer au sort une phrase dans le corpus.

Autrement dit, on a un probl√®me parce que d'une certaine fa√ßon, le mod√®le a trop bien appris‚ÄØ: on
dit qu'on est en situation de **sur-apprentissage** (*overfitting*).


Cela dit, on a vu que ne pas assez apprendre ce n'√©tait pas non plus super‚ÄØ: par exemple le mod√®le √†
bigrammes n'est pas tr√®s satisfaisant non plus. Lui semblait au contraire ne pas √™tre assez riche
pour apprendre correctement ce qu'il y avait dans les donn√©es d'entra√Ænement. On parle dans ce cas
de **sous-apprentissage** (*underfitting*).

Celui qui avait l'air d'√™tre le meilleur √©quilibre, en fait, c'√©tait le mod√®le √† trigrammes.

Mais √ßa, c'est juste notre intuition, ce qui est bien, mais limit√©. En particulier, c'est loin
d'√™tre infaillible. Ce qu'il nous faudrait ‚Äî‚ÄØcomme Newton ou Marie Sk≈Çodowska‚ÄìCurie‚ÄØ‚Äî c'est une
fa√ßon de le **quantifier**.


Autrement dit‚ÄØ: on veut moyen, √©tant donn√© un mod√®le de langue, de d√©terminer sa qualit√© sous forme
d'un **score** chiffr√© (ou **m√©trique**). On dit aussi qu'on veut pouvoir **√©valuer** ce mod√®le.

Pourquoi un score chiffr√©‚ÄØ? Pourquoi pas juste un truc qui dirait ¬´‚ÄØbien‚ÄØ¬ª ou ¬´‚ÄØpas bien‚ÄØ¬ª‚ÄØ? Pour
deux raisons‚ÄØ:

- La raison principale, c'est que √ßa permet de **comparer** des mod√®les. On ne veut pas seulement
  savoir si un mod√®le est bon‚ÄØ: on veut savoir lequel est le *meilleur*
- L'autre raison, c'est que si on fait bien les choses, on peut attribuer des **interpr√©tations**
  aux scores obtenus.
  - Le cas prototypique, ce serait un score qui serait sur une √©chelle de $0$ √† $1$, o√π
    - $0$ serait un mod√®le qui se trompe tout le temps
    - $1$ un mod√®le qui ne se trompe jamais
    - $0.5$ un mod√®le qui se trompe une fois sur deux.
    - etc.
  - On parle de score **calibr√©** et/ou **interpr√©table**.

## Comment l'on fabrique un score

### Une astuce surprenante pour √©valuer des mod√®les

Il y a un moyen tr√®s tr√®s simple d'√©valuer un mod√®le de langue (ou en fait √† peu pr√®s n'importe quel
mod√®le de TAL)‚ÄØ:

- Attrapez un‚ãÖe humain‚ãÖe
- Expliquez-lui la t√¢che (ici g√©n√©rer du texte qui soit cr√©dible **et** original)
- Montrez-lui les sorties du syst√®me
- Demandez-lui de mettre une note au syst√®me

√áa pose plusieurs probl√®mes, √©videmment.


Une solution qui permet d'am√©liorer un peu la r√©gularit√© de la proc√©dure (par exemple pour √©viter
que la note ne soit donn√©e que sur la petite partie des phrases dont votre sujet arrive √† se
souvenir), c'est de demander de donner une note *par sortie (donc ici une note par phrase) et de
faire une moyenne.

C'est pas encore parfait, mais c'est d√©j√† un peu mieux.

√âvidemment √ßa ne r√©sout pas la question de la praticit√©‚ÄØ: trouver des humain‚ãÖes dispos√©‚ãÖes √† faire
√ßa, c'est pas √©vident, c'est lent, √ßa co√ªte cher‚Ä¶


Notre objectif ici, √ßa va donc √™tre ‚Äî‚ÄØcomme souvent‚ÄØ‚Äî de trouver une fa√ßon d'automatiser ceci.


(Notez qu'en termes de recherche, comment √©valuer la g√©n√©ration de texte, c'est vraiment une
question ouverte. Si la question vous int√©resse, [la th√®se d'E.
Manning](https://esmanning.github.io/projects/project_diss/) peut √™tre un point de d√©part
int√©ressant.)

### Une solution de secours

Essayons de nous rappeler ce qu'on disait [pas plus tard que la semaine
derni√®re](../02-ngram_lms/ngram-lms-slides.py.md)


> Un mod√®le de langue, c'est un **mod√®le** qui permet d'**estimer** la **vraisemblance** d'une
> **phrase**.


On avait dit que dans un monde id√©al o√π on disposerait d'un corpus $C$ de toutes les phrases pouvant
appara√Ætre dans la langue qu'on √©tudie.


En mettant de c√¥t√© le fait que certaines phrases sont plus courantes que d'autres, ce qu'on pourrait
attendre d'un mod√®le parfait, c'est qu'il donne une vraisemblance de $1$ pour toutes les phrases de
ce corpus (puisqu'elles sont toutes possibles) et une vraisemblance de $0$ pour toutes les phrases
qui n'y sont pas (puisqu'elles ne sont pas possibles).


Un mod√®le qui donnerait une vraisemblance $p_s = 0.1$ pour une phrase $s$ qui serait dans $C$ (on
note $s‚ààC$), il aurait par exemple un score pas super pour cette phrase. Autrement dit, on peut
simplement utiliser la vraisemblance donn√©e par le mod√®le comme une m√©trique d'√©valuation‚ÄØ!


Bon, √ßa c'est sur une phrase, mais on peut facilement l'√©tendre √† l'ensemble du corpus, en faisant
une moyenne‚ÄØ:


Si on imagine qu'il y a $n$ phrases possibles dans $C$ (un tr√®s tr√®s grand $n$ donc) et qu'on les
appelle $s_1$, $s_2$, ‚Ä¶, $s_n$, le score global $M$ de notre mod√®le, on peut par exemple d√©cider que
ce serait la moyenne‚ÄØ:


\begin{equation}
    M = \frac{p_{s_1} + p_{s_2} + ‚Ä¶ + p_{s_n}}{n}
\end{equation}



**Attention**, j'insiste‚ÄØ: on *peut* **d√©cider** de **choisir** ceci comme score. Il n'y a pas de
divinit√© des mod√®les de langues qui aurait d√©cid√© que ce serait la bonne fa√ßon. Il n'y pas de
m√©trique d'√©valuation canonique et parfaite qui serait √©crite dans la trame de l'univers.

Les m√©triques d'√©valuations, scores, mesures de qualit√©s‚Ä¶ ce sont des choses cr√©√©es et choisies par
les humains. Souvent avec de bonnes raisons de faire ces choix, mais √ßa reste bien des **choix**. On
pourrait en faire d'autre, et dans ce cas pr√©cis, comme je l'ai dit plus haut, il n'y a actuellement
pas de consensus scientifique sur comment √©valuer un mod√®le de g√©n√©ration de texte de fa√ßon
*satisfaisante*.


Ici par exemple, vous remarquerez que ce score ne tient pas compte de la vraisemblance donn√©e aux
phrases impossibles (celles qui ne seraient pas dans $C$). Pour des raisons pratiques‚ÄØ: il y en a
une infinit√©‚ÄØ! Pas facile de faire une moyenne. On se contente donc du choix fait ici‚ÄØ: la moyenne
des vraisemblances des phrases de $C$.


Ici on a donc juste un exemple de score. Et on va de toute fa√ßon vite tomber sur un √©cueil.


**Vous voyez le probl√®me‚ÄØ?**


On a **toujours** pas de ¬´‚ÄØcorpus de toutes les phrases pouvant appara√Ætre dans la langue qu'on
√©tudie‚ÄØ¬ª


Comment on fait alors‚ÄØ?


Et bien comme d'habitude‚ÄØ: on prend un √©chantillon. Un corpus, quoi. On va essayer de le prendre le
plus repr√©sentatif possible de la langue. C'est le mieux qu'on puisse faire de toute fa√ßon.


Et tout le monde est content. Bon il faut se souvenir de comment on obtient $p_s$, mais on va
vite le revoir.


### Corpus d'√©valuation


√áa tombe bien, on a d√©j√† sous la main un √©chantillon de la langue‚ÄØ: notre corpus d'entra√Ænement‚ÄØ!


Du coup on a qu'√† l'utiliser pour √©valuer notre mod√®le, non‚ÄØ?


Quoi‚ÄØ? Encore un probl√®me‚ÄØ?


Ben oui, souvenez-vous du mod√®le 5-gramme


Le probl√®me, c'est que si on fait- √ßa, un mod√®le qui apprend juste le corpus par c≈ìur va obtenir un
super score, puisqu'il a eu acc√®s √† ces donn√©es-l√† pour apprendre.


Alors pourquoi pas, mais imaginez que vous ayez deux mod√®les. Un appris en utilisant *Frankenstein*,
l'autre en utilisant *Le Ventre de Paris*. Si vous les √©valuez en regardant s'ils pr√©disent
correctement *Le Ventre de Paris*, il y en a un qui a un avantage d√©loyal. Autrement dit on a une
√©valuation qui ne nous dira pas vraiment lequel de ces mod√®les aurait le meilleur score dans
l'absolu, dans le monde id√©al o√π on pourrait le tester sur ce corpus magique qui contient toute la
langue.


Pour que ce soit √©quitable, on va donc plut√¥t pr√©f√©rer utiliser comme √©chantillon pour l'√©valuation
un corpus diff√©rent du corpus d'entra√Ænement, si possible m√™me un qui n'a aucune phrase en commun.
On appellera ce deuxi√®me corpus le **corpus de test** ou d'**√©valuation**.


## Perplexit√©

### üé≤ Vraisemblance d'une phrase üé≤


Rappel‚ÄØ: un mod√®le de langue √† trigrammes calcule la vraisemblance d'une phrase $s= w_1, ‚Ä¶, w_n$ de
la fa√ßon suivante‚ÄØ:

\begin{equation}
    p_s = P(w_0) √ó P(w_1 | w_0) √ó P(w2 | w_0, w_1) √ó P(w_3 | w_1, w_2) √ó ‚Ä¶ √ó P(w_n | w_{n-2}, w_{n-1})
\end{equation}

avec


\begin{equation}
    P(w_i | w_{i-2}, w_{i-1}) = \frac{\text{Fr√©quence du trigramme $w_{i-2}, w_{i-1}, w_i$}}{\text{Fr√©quence de l'unigramme $w_i$}}
\end{equation}


Et pour $P(w_0)$ $P(w_1 | w_0)$, on peut tricher en les √©crivant $P(w_0 |¬†\text{<s>}, \text{<s>})$
et $P(w_1 | \text{<s>}, w_0)$. Ce serait aussi bien de compter que $w_n = \text{</s>}$.


√âcrire une fonction `sent_likelihood`, qui prend en argument des probas de n-grammes, une phrase
sous forme de liste de cha√Ænes de caract√®res (et √©ventuellement `n` si vous ne voulez pas utiliser
mon astuce sale du d√©but) et renvoie la vraisemblance de cette phrase.



```python
def sent_likelihood(ngram_probs, sent, n):
    pass  # √Ä toi de coder

assert sent_likelihood(trigram_probs, ["p√©nitentes", ",", "que", "prenez-vous", "?"], 3) == 3.9225257586711874e-14
```

### Log-vraisemblance


Il y a un petit souci avec ce qu'on a fait, li√© aux limitations du [calcul en virgule
flottante](https://fr.wikipedia.org/wiki/Virgule_flottante), qui est la fa√ßon dont nos machines
repr√©sentent et manipulent les nombres non-entiers. Imaginez qu'on essaie de calculer la
vraisemblance d'une phrase de $100$ mots, ou la probabilit√© de chaque nouveau mot est de $0.0002$
(ou `2e-4`, soit $2√ó10^{-4}$)

```python
accumulator = 1.0
for i in range(100):
    accumulator *= 0.0002
    print(accumulator)
```

Vous voyez le probl√®me‚ÄØ? On a multipli√© que des nombres non-nuls, le r√©sultat ne devrait donc pas
pouvoir √™tre $0$. Et pourtant, comme la pr√©cision de la machin est limit√©e, c'est bien ce qu'on
finit par obtenir. (On parle d'*underflow*).


On va utiliser une astuce de maths ici‚ÄØ: on va passer au
[logarithme](https://fr.wikipedia.org/wiki/Logarithme). C'est-√†-dire qu'au lieu de calculer la
vraisemblance $p_s$ de la phrase $s$, on va calculer sa **log-vraisemblance** $\log(p_s)$.


Pour l'instant, pas besoin de se casser la t√™te sur ce que c'est que le logarithme. Les points
importants ici sont‚ÄØ:

- Il existe une fonction (au sens math√©matique), not√©e $\log$, elle est accessible en Python comme
  `math.log`.
- $\log$ est strictement croissante, c'est-√†-dire que si $x < y$, alors $\log(x) < \log(y)$. √áa nous
  assure que si on trouve que si un mod√®le est meilleur qu'un autre en termes de log-vraisemblance,
  il l'est aussi en termes de vraisemblance tout cours.
- $\log(a√ób) = \log(a) + \log(b)$, ce qui va nous permettre de calculer facilement $\log(p_s)$ et
  diminuant tr√®s grandement le risque d'*underflow*.

```python
import math

print(math.log(2))
print(math.log(1))
```

Attention en revanche‚ÄØ: $\log(0) = -‚àû$, donc ceci ne marche pas

```python
print(math.log(0))
```

Mais c'est pas grave‚ÄØ: on a par construction pas de mots de probabilit√© $0$.

### ü§òüèª Calculer la perplexit√© ü§òüèª

1\. √âcrire une fonction `sent_loglikelihood`, qui les m√™mes arguments que `sent_likelihood` et
renvoie la **log-vraisemblance** de cette phrase.


```python
def sent_loglikelihood(ngram_probs, sent, n):
    pass  # √Ä toi de coder

assert sent_loglikelihood(trigram_probs, ["p√©nitentes", ",", "que", "prenez-vous", "?"], 3) == -30.86945552941164
```


2\. √âcrire une fonction `avg_log_likelihood`, qui prend qui prend en argument des probas de
n-grammes, un chemin vers un corpus et `n` et renvoie la vraisemblance moyenne de ce corpus estim√©e
par le mod√®le √† n-grammes correspondant √† ces probas (autrement dit, la moyenne des
log-vraisemblances de phrases). Testez sur *Le Ventre de Paris* (non, on l'a dit, c'est pas une
√©valuation juste, mais √ßa va nous permettre de voir si √ßa marche).

```python
def avg_log_likelihood(ngram_probs, file_path, n):
    pass  # √Ä toi de coder

assert avg_log_likelihood(bigram_probs, "data/zola_ventre-de-paris.txt", 2) == -56.321217776181875
assert avg_log_likelihood(trigram_probs, "data/zola_ventre-de-paris.txt", 3) == -81.20968449380536
assert avg_log_likelihood(pentagram_probs, "data/zola_ventre-de-paris.txt", 5) == -88.25016939038316
```


## Mots inconnus et √©valuation en g√©n√©ral

√Ä vous de jouer maintenant¬†!

Coder l'√©valuation sur [*Le Rouge et le Noir*](data/rouge_noir.txt) (il
se trouve dans `"data/rouge_noir.txt"`) des mod√®les de langues appris sur *Le Ventre de Paris*.
Attention, vous allez vous heurter √† des probl√®mes de vocabulaires incompatibles et de n-grammes
inexistants. Pour les r√©soudre, vous allez devoir vous servir des infos des sections 3.4 et 3.5.1 de
[*Speech and Language Processing*](https://web.stanford.edu/~jurafsky/slp3/3.pdf).
